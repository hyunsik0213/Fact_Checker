{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3a17a7b5",
      "metadata": {
        "id": "3a17a7b5"
      },
      "source": [
        "Fact_Checker: 기사 신뢰도 평가 서비스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a24d4b05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a24d4b05",
        "outputId": "f28db4ee-82d9-41c5-9064-7125c3fffddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.9/837.9 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install google-generativeai feedparser trafilatura python-dateutil scikit-learn beautifulsoup4 lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bfa7ab7e",
      "metadata": {
        "id": "bfa7ab7e"
      },
      "outputs": [],
      "source": [
        "import os, re, json, urllib.parse, logging\n",
        "from typing import List, Dict, Any, Tuple\n",
        "import feedparser, trafilatura, requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import google.generativeai as genai\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "logging.getLogger(\"trafilatura\").setLevel(logging.ERROR)\n",
        "\n",
        "def clean_text(s: str) -> str:\n",
        "    if not s:\n",
        "        return \"\"\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s.strip()\n",
        "\n",
        "def safe_truncate(s: str, max_chars: int = 8000) -> str:\n",
        "    if not s:\n",
        "        return s\n",
        "    return s[:max_chars]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94a4ab13",
      "metadata": {
        "collapsed": true,
        "id": "94a4ab13"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY = input(\"Google API Key: \").strip()\n",
        "if not GOOGLE_API_KEY:\n",
        "    raise ValueError(\"API Key required.\")\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "SYSTEM_INSTRUCTION = (\n",
        "    \"너는 한국어 뉴스를 다루는 팩트체커다. \"\n",
        "    \"주장(claim)을 명확히 추출하고, 상대 기사와 비교해 사실 일치/불일치, 누락/과장 여부를 근거와 함께 밝힌다. \"\n",
        "    \"출력은 가능하면 간결하고 구조화한다.\"\n",
        ")\n",
        "MODEL_NAME = \"gemini-2.5-pro\"\n",
        "model = genai.GenerativeModel(MODEL_NAME, system_instruction=SYSTEM_INSTRUCTION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8d69de73",
      "metadata": {
        "id": "8d69de73"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from trafilatura.metadata import extract_metadata as t_extract_metadata\n",
        "except Exception:\n",
        "    t_extract_metadata = None\n",
        "\n",
        "def fetch_article(url: str) -> Dict[str, Any]:\n",
        "    title, text = \"\", \"\"\n",
        "    try:\n",
        "        downloaded = trafilatura.fetch_url(url, no_ssl=True)\n",
        "        if downloaded:\n",
        "            justtext = trafilatura.extract(\n",
        "                downloaded,\n",
        "                include_comments=False,\n",
        "                include_tables=False,\n",
        "                favor_recall=True\n",
        "            )\n",
        "            if justtext:\n",
        "                text = clean_text(justtext)\n",
        "            if t_extract_metadata:\n",
        "                try:\n",
        "                    meta = t_extract_metadata(downloaded)\n",
        "                    if meta and getattr(meta, \"title\", None):\n",
        "                        title = meta.title\n",
        "                except Exception:\n",
        "                    pass\n",
        "        if not text:\n",
        "            resp = requests.get(\n",
        "                url, timeout=12,\n",
        "                headers={\"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 Chrome/120 Safari/537.36\"}\n",
        "            )\n",
        "            resp.raise_for_status()\n",
        "            soup = BeautifulSoup(resp.text, \"lxml\")\n",
        "            root = soup.find(\"article\") or soup.find(attrs={\"role\":\"main\"}) or soup\n",
        "            ps = [p.get_text(\" \", strip=True) for p in root.find_all(\"p\")]\n",
        "            if not ps:\n",
        "                ps = [p.get_text(\" \", strip=True) for p in soup.find_all(\"p\")]\n",
        "            text = clean_text(\" \".join(ps))\n",
        "            if not title:\n",
        "                if soup.title and soup.title.string:\n",
        "                    title = soup.title.get_text(strip=True)\n",
        "                else:\n",
        "                    og = soup.find(\"meta\", property=\"og:title\")\n",
        "                    if og and og.get(\"content\"):\n",
        "                        title = og[\"content\"]\n",
        "        return {\"url\": url, \"title\": title or \"(제목 없음)\", \"content\": text}\n",
        "    except Exception as e:\n",
        "        return {\"url\": url, \"title\": \"(에러)\", \"content\": \"\", \"error\": str(e)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "557d599a",
      "metadata": {
        "id": "557d599a"
      },
      "outputs": [],
      "source": [
        "def extract_keywords_with_gemini(text: str) -> List[str]:\n",
        "    prompt = (\n",
        "        \"다음 본문에서 핵심 키워드/개체명 5~10개를 한국어로 뽑아줘. \"\n",
        "        \"너무 일반적인 단어는 제외하고, 고유명사를 우선한다. \"\n",
        "        \"출력은 JSON 배열(문자열 리스트)로만 응답해.\\n\\n본문:\\n\" + text[:6000]\n",
        "    )\n",
        "    resp = model.generate_content(prompt, generation_config={\"response_mime_type\": \"application/json\"})\n",
        "    try:\n",
        "        data = json.loads(resp.text or \"[]\")\n",
        "    except Exception:\n",
        "        data = []\n",
        "    out, seen = [], set()\n",
        "    for k in data:\n",
        "        k2 = clean_text(str(k))\n",
        "        if k2 and k2.lower() not in seen:\n",
        "            seen.add(k2.lower()); out.append(k2)\n",
        "    return out[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7bcb891f",
      "metadata": {
        "id": "7bcb891f"
      },
      "outputs": [],
      "source": [
        "def google_news_search_rss_query(q: str, lang=\"ko\", country=\"KR\", max_items=20):\n",
        "    query = urllib.parse.quote(q)\n",
        "    url = f\"https://news.google.com/rss/search?q={query}&hl={lang}&gl={country}&ceid={country}:{lang}\"\n",
        "    feed = feedparser.parse(url)\n",
        "    items = []\n",
        "    for entry in feed.entries[:max_items]:\n",
        "        items.append({\n",
        "            \"title\": entry.get(\"title\", \"\"),\n",
        "            \"link\": entry.get(\"link\", \"\"),\n",
        "            \"published\": entry.get(\"published\", \"\"),\n",
        "            \"source\": entry.get(\"source\", {}).get(\"title\", \"\"),\n",
        "        })\n",
        "    return items, {\"rss_url\": url, \"query\": q}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ff6a14df",
      "metadata": {
        "id": "ff6a14df"
      },
      "outputs": [],
      "source": [
        "def rank_similar_articles(src_text: str, candidate_links: List[str], top_k=3):\n",
        "    docs = [src_text]\n",
        "    metas = []\n",
        "    for link in candidate_links:\n",
        "        art = fetch_article(link)\n",
        "        metas.append(art)\n",
        "        docs.append(art.get(\"content\",\"\"))\n",
        "    vectorizer = TfidfVectorizer(max_features=6000, ngram_range=(1,2))\n",
        "    tfidf = vectorizer.fit_transform(docs)\n",
        "    sims = cosine_similarity(tfidf[0:1], tfidf[1:]).flatten()\n",
        "    idxs = sims.argsort()[::-1]\n",
        "    picked = []\n",
        "    for i in idxs:\n",
        "        if len(picked) >= top_k:\n",
        "            break\n",
        "        picked.append((metas[i], float(sims[i])))\n",
        "    return picked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fbf7e5d6",
      "metadata": {
        "id": "fbf7e5d6"
      },
      "outputs": [],
      "source": [
        "EVAL_SCHEMA = {\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"claims\": {\n",
        "      \"type\": \"array\",\n",
        "      \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"text\": {\"type\": \"string\"},\n",
        "          \"verdict\": {\"type\": \"string\", \"enum\": [\"일치\", \"부분일치\", \"불일치\", \"검증불가\"]},\n",
        "          \"evidence\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": {\n",
        "              \"type\": \"object\",\n",
        "              \"properties\": {\n",
        "                \"title\": {\"type\": \"string\"},\n",
        "                \"url\": {\"type\": \"string\"},\n",
        "                \"note\": {\"type\": \"string\"}\n",
        "              },\n",
        "              \"required\": [\"url\"]\n",
        "            }\n",
        "          }\n",
        "        },\n",
        "        \"required\": [\"text\",\"verdict\",\"evidence\"]\n",
        "      }\n",
        "    },\n",
        "    \"omissions_or_exaggerations\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "    \"reliability_score\": {\"type\": \"number\"},\n",
        "    \"summary\": {\"type\": \"string\"}\n",
        "  },\n",
        "  \"required\": [\"claims\",\"reliability_score\",\"summary\"]\n",
        "}\n",
        "\n",
        "def assess_reliability_with_gemini(src_meta: Dict[str,Any], similars: List[Tuple[Dict[str,Any], float]]) -> Dict[str,Any]:\n",
        "    src_text = safe_truncate(src_meta.get(\"content\",\"\"), 12000)\n",
        "    comp = []\n",
        "    for i,(m,sim) in enumerate(similars, start=1):\n",
        "        comp.append({\n",
        "            \"rank\": i,\n",
        "            \"title\": m.get(\"title\",\"\"),\n",
        "            \"url\": m.get(\"url\",\"\"),\n",
        "            \"similarity\": round(sim, 4),\n",
        "            \"content\": safe_truncate(m.get(\"content\",\"\"), 6000)\n",
        "        })\n",
        "    schema_json = json.dumps(EVAL_SCHEMA, ensure_ascii=False)\n",
        "    prompt = (\n",
        "        \"아래 (A) 원문 기사와 (B) 유사 기사들을 비교하여 **JSON**으로만 답하라.\\n\"\n",
        "        \"- 각 주장(claim)에 대해 verdict(일치/부분일치/불일치/검증불가)와 evidence(제목/URL/메모)를 작성하라.\\n\"\n",
        "        \"- omissions_or_exaggerations 배열에 누락/과장 포인트를 간결히 담아라.\\n\"\n",
        "        \"- reliability_score(0~100), summary(<=5줄)를 포함하라.\\n\"\n",
        "        f\"- JSON 스키마: {schema_json}\\n\\n\"\n",
        "        f\"(A) 원문: 제목={src_meta.get('title','')}, URL={src_meta.get('url','')}\\n본문(요약용): {src_text}\\n\\n\"\n",
        "        f\"(B) 유사 기사 Top-{len(comp)}: {json.dumps(comp, ensure_ascii=False)}\"\n",
        "    )\n",
        "    resp = model.generate_content(prompt, generation_config={\"response_mime_type\": \"application/json\"})\n",
        "    try:\n",
        "        data = json.loads(resp.text or \"{}\")\n",
        "    except Exception:\n",
        "        data = {\"summary\": \"(파싱 실패)\", \"raw\": resp.text}\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7307106d",
      "metadata": {
        "id": "7307106d"
      },
      "outputs": [],
      "source": [
        "def _verdict_score(v: str) -> float:\n",
        "    table = {\"일치\": 1.0, \"부분일치\": 0.5, \"검증불가\": 0.0, \"불일치\": -1.5}\n",
        "    return table.get(v, 0.0)\n",
        "\n",
        "def compute_reliability_score_deterministic(\n",
        "    evaluation: Dict[str, Any],\n",
        "    similars: List[Tuple[Dict[str, Any], float]],\n",
        "    claim_weights: List[float] = None,\n",
        "    omission_penalty_per_item: float = 5.0,\n",
        "    omission_penalty_cap: float = 20.0,\n",
        "    similarity_center: float = 0.50,\n",
        "    similarity_scale: float = 10.0,\n",
        ") -> Dict[str, Any]:\n",
        "    claims = evaluation.get(\"claims\", [])\n",
        "    if not claims:\n",
        "        return {\"score\": 40.0, \"notes\": \"no-claims: fallback\"}\n",
        "    n = len(claims)\n",
        "    weights = claim_weights if (claim_weights and len(claim_weights) == n) else [1.0]*n\n",
        "    raw = 0.0\n",
        "    wsum = 0.0\n",
        "    for i, c in enumerate(claims):\n",
        "        v = str(c.get(\"verdict\", \"\")).strip()\n",
        "        s = _verdict_score(v)\n",
        "        w = float(weights[i])\n",
        "        raw += s * w\n",
        "        wsum += w\n",
        "    avg_score = raw / max(wsum, 1e-6)\n",
        "    base = (avg_score + 1.5) / 2.5 * 100.0\n",
        "    base = max(0.0, min(100.0, base))\n",
        "    om_cnt = len(evaluation.get(\"omissions_or_exaggerations\", []) or [])\n",
        "    om_pen = min(omission_penalty_cap, omission_penalty_per_item * om_cnt)\n",
        "    after_omissions = max(0.0, base - om_pen)\n",
        "    if similars:\n",
        "        avg_sim = sum(s for _, s in similars) / len(similars)\n",
        "    else:\n",
        "        avg_sim = similarity_center\n",
        "    sim_delta = (avg_sim - similarity_center) * (2 * similarity_scale)\n",
        "    final = max(0.0, min(100.0, after_omissions + sim_delta))\n",
        "    notes = f\"avg={avg_score:.2f} base={base:.1f} -om{om_pen:.1f} simΔ={sim_delta:+.1f} → {final:.1f}\"\n",
        "    return {\"score\": final, \"notes\": notes}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6015f8de",
      "metadata": {
        "id": "6015f8de"
      },
      "outputs": [],
      "source": [
        "def fact_check(url: str, lang=\"ko\", country=\"KR\", max_candidates: int = 15) -> Dict[str,Any]:\n",
        "    src = fetch_article(url)\n",
        "    if not src.get(\"content\"):\n",
        "        raise RuntimeError(f\"원문 본문 수집 실패: {src.get('error','본문 비어있음')}\")\n",
        "    keywords = extract_keywords_with_gemini(src[\"content\"])\n",
        "    query_str = src.get(\"title\") or \" \".join(keywords)\n",
        "    items, search_meta = google_news_search_rss_query(query_str, lang=lang, country=country)\n",
        "    links = [it[\"link\"] for it in items if it.get(\"link\")]\n",
        "    picked = rank_similar_articles(src[\"content\"], links[:max_candidates], top_k=3)\n",
        "    eval_json = assess_reliability_with_gemini(src, picked)\n",
        "    score_patch = compute_reliability_score_deterministic(eval_json, picked)\n",
        "    eval_json[\"reliability_score\"] = score_patch[\"score\"]\n",
        "    eval_json[\"score_notes\"] = score_patch[\"notes\"]\n",
        "    top3_public = [{\"title\": m.get(\"title\",\"\"), \"url\": m.get(\"url\",\"\")} for (m,sim) in picked]\n",
        "    return {\n",
        "        \"input_url\": url,\n",
        "        \"source\": src,\n",
        "        \"keywords\": keywords,\n",
        "        \"search_meta\": search_meta,\n",
        "        \"candidates_found\": len(links),\n",
        "        \"top3\": top3_public,\n",
        "        \"top3_internal\": picked,\n",
        "        \"evaluation\": eval_json\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "타켓 기사 URL 주소를 받아 키워드 추출 및 유사 기사 탐색"
      ],
      "metadata": {
        "id": "bgCOWGoCiGjJ"
      },
      "id": "bgCOWGoCiGjJ"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7d37bd30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "7d37bd30",
        "outputId": "76f3e7bb-ea25-4efb-ef3b-cc8a6be525e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "뉴스 URL: https://www.chosun.com/economy/industry-company/2025/10/30/PMJQJI4IHRGZ3IZ4QLJPTGER74/?outputType=amp\n",
            "\n",
            "키워드: 젠슨 황, 이재용, 정의선, 엔비디아, 삼성전자, 현대차그룹, 깐부치킨, 치맥, 지포스, 이건희\n",
            "\n",
            "유사 기사 Top3:\n",
            "1. https://news.google.com/rss/articles/CBMieEFVX3lxTE41VUlXZG03Wmcwai1OQmlqaGNUZmhWbnpaTWRGclAtZGtkMUh3Q0JUSFMwcTE5Z2hfOVhoYkRISERuWUdCbm5Dd1c0QlVSeU1HQzRrZmlxdEg1enlCdUE3MzM5emUweHlmQ0VCQlR2eFFvZE8xRVV1Sg?oc=5\n",
            "2. https://news.google.com/rss/articles/CBMiU0FVX3lxTFAwa3l5WUJCQVNPenVfLWFlRFFkcTZFSUd4by11SlRjTklGcmd5NW9MV00tZmVOMEpUQW5SeVFnWjEzbWFwRzM2TUFQSGVYLUY2M1Fj?oc=5\n",
            "3. https://news.google.com/rss/articles/CBMieEFVX3lxTE5hSjhON29FQVI4ZzJ0MEh2TXMySV9qWWlLaFE2Sng0R0xsQlhWRjNpMDFUVGpoQ0tFZzN6R3JNdmNrTFZObHBwbXhjck1LeVdjN2hidmVsNzhxZUk1QkpBSEo1SE51cXpJQWtWcVVFWERkMnNsY0RnZg?oc=5\n"
          ]
        }
      ],
      "source": [
        "input_url = input(\"뉴스 URL: \").strip()\n",
        "if not input_url:\n",
        "    raise ValueError(\"URL required.\")\n",
        "res = fact_check(input_url)\n",
        "print(\"\\n키워드:\", \", \".join(res[\"keywords\"]))\n",
        "print(\"\\n유사 기사 Top3:\")\n",
        "for i, item in enumerate(res[\"top3\"], start=1):\n",
        "    print(f\"{i}. {item['url']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2652899a",
      "metadata": {
        "id": "2652899a"
      },
      "source": [
        "결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "896c93bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "896c93bf",
        "outputId": "e0c740bb-931b-4446-88e7-dfd2451a15af"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**신뢰성 점수: 75.0/100**\n\n**요약**\n젠슨 황 엔비디아 CEO, 이재용 삼성전자 회장, 정의선 현대차그룹 회장이 10월 29일 저녁 서울의 한 치킨집에서 회동했다. 이들은 화기애애한 분위기 속에서 AI 분야 협력을 다짐했으며, 이후 지포스 25주년 행사에 함께 참석해 'AI 깐부' 동맹을 과시했다. 원문 기사는 회동 장면과 대화 내용을 상세히 전했으나, 실제 회동 날짜를 29일이 아닌 30일로 잘못 표기하는 오류가 있었다.\n\n**주장별 검증**\n\n주장1: 젠슨 황, 이재용, 정의선이 10월 30일 서울 삼성동 깐부치킨에서 '치맥' 회동을 가졌다.\n\n판정: 부분일치\n\n\n근거: [황·이재용·정의선, 삼성동서 '치맥 회동'…AI동맹 과시](https://www.joongang.co.kr/article/25293444) — 다수 언론에서 회동 날짜를 10월 29일 저녁으로 보도했다. 원문 기사가 언급한 30일은 기사 발행일로, 실제 회동 날짜와 차이가 있다.\n\n근거: [[영상] 젠슨 황·이재용·정의선 '깜짝 치맥'…'AI 깐부' 맺었다](https://www.yna.co.kr/view/AKR20241029175351003) — 연합뉴스 역시 회동 시점을 29일 저녁으로 특정하여 보도했다.\n\n주장2: 황 CEO는 지포스 25주년 행사에서 '이재명 대통령 초청으로 APEC에 왔다'고 말했다.\n\n판정: 일치\n\n\n근거: [젠슨 황 “이재명 대통령 초청으로 와”…‘AI 깐부’ 맺은 이재용·정의선과 ‘치맥’](https://www.hani.co.kr/arti/economy/it/1165158.html) — 원문 기사의 인용은 사실이다. 다수 언론이 해당 발언을 보도했으며, 현직 대통령(윤석열)의 이름을 잘못 말한 '실수'로 분석하고 있다.\n\n주장3: 황 CEO는 이재용, 정의선 회장에게 사인한 위스키와 엔비디아의 초소형 AI 수퍼컴퓨터 'DGX 스파크'를 선물했다.\n\n판정: 일치\n\n\n근거: [젠슨 황이 이재용·정의선에 선물한 'DGX 스파크' 뭐길래…가격이](https://news.mt.co.kr/mtview.php?no=2024103009131920786) — 선물 품목(하쿠슈 25년 위스키, DGX 스파크)과 사인 등의 세부 내용은 다른 언론 보도와 일치한다.\n\n주장4: 이재용 회장 측이 치킨집 현장에 있던 다른 손님들의 저녁 식사 비용 약 180만원을 결제했다.\n\n판정: 일치\n\n\n근거: [젠슨 황 \"1차는 이재용이 쏜다\"…180만원 긁었다](https://www.hankyung.com/article/202410295115g) — 황 CEO가 '1차는 이들이 쏜다'고 말한 것과 이재용 회장 측이 약 180만원을 결제했다는 일화는 여러 매체에서 공통적으로 다루고 있다.\n\n<small>avg=0.88 base=95.0 -om10.0 simΔ=-10.0 → 75.0</small>"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "def render_report(res: Dict[str,Any]):\n",
        "    ev = res.get(\"evaluation\", {})\n",
        "    lines = []\n",
        "    lines.append(f\"**신뢰성 점수: {ev.get('reliability_score','-')}/100**\")\n",
        "    lines.append(\"\")\n",
        "    lines.append(\"**요약**\")\n",
        "    lines.append(ev.get(\"summary\",\"(요약 없음)\"))\n",
        "    lines.append(\"\")\n",
        "    lines.append(\"**주장별 검증**\")\n",
        "    lines.append(\"\")\n",
        "\n",
        "    claims = ev.get(\"claims\", [])\n",
        "    if not claims:\n",
        "        lines.append(\"주장 데이터 없음\\n\")\n",
        "\n",
        "    for idx, c in enumerate(claims, start=1):\n",
        "        lines.append(f\"주장{idx}: {c.get('text','')}\")\n",
        "        lines.append(\"\")\n",
        "        lines.append(f\"판정: {c.get('verdict','')}\")\n",
        "        lines.append(\"\")\n",
        "        for e in c.get(\"evidence\", []):\n",
        "            title = e.get(\"title\",\"\")\n",
        "            url = e.get(\"url\",\"\")\n",
        "            note = e.get(\"note\",\"\")\n",
        "            line = f\"근거: [{title or url}]({url})\"\n",
        "            if note:\n",
        "                line += f\" — {note}\"\n",
        "                lines.append(\"\")\n",
        "            lines.append(line)\n",
        "        lines.append(\"\")\n",
        "\n",
        "    sn = ev.get(\"score_notes\",\"-\")\n",
        "    lines.append(f\"<small>{sn}</small>\")\n",
        "\n",
        "    display(Markdown(\"\\n\".join(lines)))\n",
        "\n",
        "render_report(res)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1404b971",
      "metadata": {
        "id": "1404b971"
      },
      "source": [
        "<small>끝.</small>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}